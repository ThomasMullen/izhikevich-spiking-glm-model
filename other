"""
fit a poisson glm to a tonic spiking step function

notes:
----
# generate design matrix

# fit glm and get parameters

# simulate model

# compare with Izhikevich neuron - tonic spike
"""
import statsmodels.api as sm
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import hankel
from scipy.interpolate import interp1d

from Izhikevich import *
from plotting import plot_glm_matrices, plot_matrix

plt.style.use("https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle")

plot_path = "/Users/tom/Imbizo/Week_03/izhikevich-neuron/plots/tonic_spiking"
# seeds = np.random.randint(0,1000000, 10)
seeds = [389469, 169149, 592324, 102934, 896059, 437868, 792533, 927135,
        69193, 646798]
#   T = len(stim)  # Total number of timepoints (hint: number of stimulus frames)
#   X = np.zeros((T, d))
#   for t in range(T):
#       X[t] = padded_stim[t : t + d]


#   return X


def make_stim_design_matrix(stim, n_filter=6):
    """make a stimulus design matrix based on current input I`

    Args:
        stim (array): current input
        n_filter (int, optional): size of filter kernel. Defaults to 6.

    Returns:
        array: design matrix shape (stim x filter)
    """
    padded_stim = np.hstack([np.zeros(n_filter-1), stim])
    design_stim_matrix = hankel(padded_stim[:-n_filter+1], stim[-n_filter:])
    return design_stim_matrix


def make_history_matrix(spike_count, n_filter=5, n_lags=1):
    """make a history dependent design matrix based on input spike counts

    Args:
        spike_count (array): past spike counts
        n_filter (int, optional): size of kernel. Defaults to 5.
        n_lags (int, optional): numberof timesteps in past. Defaults to 1.

    Returns:
        array: design matrix shape (stim x filter)
    """
    padded_spike_count = np.hstack([np.zeros(n_filter-1+n_lags), spike_count[:-n_lags]])
    design_hist_matrix = hankel(padded_spike_count[:-n_filter+1], spike_count[-n_filter:])
    return design_hist_matrix


T = 100000 # units ms
dt = 0.1
N = int(T/dt)
time = Time(T=T, tt=np.arange(0,T, dt), dt=dt)
x0 = np.array([-70, -14]) # initial state


bin_size=5000

n_filter = 10
n_hist_filter = 9



LogLike=[]
stim_filts=[]
hist_filts=[]
for seed_ in seeds:
    np.random.seed(seed_)
    dynamics = generate_izhikevich(x0, behaviour_types['tonic spiking'], time, 
                                        bin_size=bin_size, I_func=set_rand_step_I2,
                                        show_plt=False,)
    # design matrix
    design_stim_matrix = make_stim_design_matrix(stim=dynamics.I[::dynamics.bin_wid], n_filter=n_filter)
    design_hist_matrix = make_history_matrix(dynamics.spike_counts, 
                                            n_filter=n_hist_filter, n_lags=1)
    design_matrix = np.concatenate([design_stim_matrix, design_hist_matrix], axis=1)

    # add offsets
    design_matrix_offset = np.hstack((np.ones((len(dynamics.I[::dynamics.bin_wid]),1)), design_matrix))

    # fit Poisson GLM
    glm_poisson_exp = sm.GLM(endog=dynamics.spike_counts, exog=design_matrix_offset,
                            family=sm.families.Poisson())

    pGLM_results = glm_poisson_exp.fit(max_iter=1000, tol=1e-6, tol_criterion='params')

    # get filters
    glm_const = pGLM_results.params[0]
    glm_filter_stim = pGLM_results.params[1:n_filter+1]
    glm_filter_hist = pGLM_results.params[-n_hist_filter:]
    hist_filts.append(glm_filter_hist)
    stim_filts.append(glm_filter_stim)
    LogLike.append(pGLM_results.llf)
    
    
mean_stim_filter = np.mean(stim_filts.T, axis=1)
mean_hist_filter = np.mean(hist_filts.T, axis=1)
fig, (ax1, ax2) = plt.subplots(ncols=2,
                               sharey=True,
                               )
ax1.plot((-1*np.arange(0,len(mean_stim_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], stim_filts.T/np.linalg.norm(stim_filts.T, axis=1), lw=.5, alpha=.5)
ax1.plot((-1*np.arange(0,len(mean_stim_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_stim_filter/np.linalg.norm(mean_stim_filter), c='k', label="mean")
ax1.plot((-1*np.arange(0,len(mean_stim_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_stim_filter*0, linestyle='--', c='gray')
ax1.set(xlabel="Time",
        ylabel="",
        title="Stimulus filter")
ax1.legend()

for i in range(10):
    ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], hist_filts[i]/np.linalg.norm(hist_filts[i]), lw=.5, alpha=.5)
ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_hist_filter/np.linalg.norm(mean_hist_filter), c='k', label="mean")
ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_hist_filter*0, linestyle='--', c='gray')
ax2.legend()
ax2.set(xlabel="Time",
        ylabel="",
        title="History filter")
fig.savefig(f"{plot_path}/ave_filters.svg")


ax2.plot(hist_filts.T, lw=.5, alpha=.5)
ax2.plot(np.mean(hist_filts.T, axis=1), c='k', label="mean")


fig, ax =plt.subplots()
for i in range(10):
    ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], hist_filts[i]/np.linalg.norm(hist_filts[i]), lw=.5, alpha=.5)
ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_hist_filter/np.linalg.norm(mean_hist_filter), c='k', label="mean")
ax2.plot((-1*np.arange(0,len(mean_hist_filter), 1)*dynamics.bin_wid*time.dt/10)[::-1], mean_hist_filter*0, linestyle='--', c='gray')